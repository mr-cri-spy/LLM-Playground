{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPX5Ve+wT8ma8XECXDmSGYx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-cri-spy/LLM-Playground/blob/main/LoRA_for_Large_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfD3nrYXoIxe",
        "outputId": "0faefb0c-f719-4d72-a066-bf20bb6ffeda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.4.0\n",
            "  Using cached torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Collecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Using cached triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.8.93)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Using cached torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl (797.2 MB)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tea"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "FTKSJyHyzNu9",
        "outputId": "236dbd48-42ff-4e1a-91d8-0ff9326a41e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tea\n",
            "  Downloading tea-0.1.7-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting psutil~=5.8.0 (from tea)\n",
            "  Downloading psutil-5.8.0.tar.gz (470 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m470.9/470.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytz~=2021.3 (from tea)\n",
            "  Downloading pytz-2021.3-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tzlocal~=3.0 (from tea)\n",
            "  Downloading tzlocal-3.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Downloading tea-0.1.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m503.5/503.5 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzlocal-3.0-py3-none-any.whl (16 kB)\n",
            "Building wheels for collected packages: psutil\n",
            "  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psutil: filename=psutil-5.8.0-cp312-cp312-linux_x86_64.whl size=286460 sha256=d0b0d39a8acbec161c54f4fc9cb1aa40777be16ad85b7ae90b5735789b01b852\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/44/fb/a1791dcea454dc57abdd0d71d6e9588574286cb6db373a2627\n",
            "Successfully built psutil\n",
            "Installing collected packages: pytz, tzlocal, psutil, tea\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: tzlocal\n",
            "    Found existing installation: tzlocal 5.3.1\n",
            "    Uninstalling tzlocal-5.3.1:\n",
            "      Successfully uninstalled tzlocal-5.3.1\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.15.0 requires pytz>=2022.7, but you have pytz 2021.3 which is incompatible.\n",
            "ibis-framework 9.5.0 requires pytz>=2022.7, but you have pytz 2021.3 which is incompatible.\n",
            "google-adk 1.11.0 requires tzlocal<6.0,>=5.3, but you have tzlocal 3.0 which is incompatible.\n",
            "yfinance 0.2.65 requires pytz>=2022.5, but you have pytz 2021.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed psutil-5.8.0 pytz-2021.3 tea-0.1.7 tzlocal-3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              },
              "id": "c98f8197d9854b8baa5b47fc331a2077"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Check so there is a gpu available, a T4(free tier) will NOT be enough for an 8B parameter model\n",
        "# This trainig will require at leas 20GB of VRAM, so for Colab an L4 or A100 GPU will be needed\n",
        "assert (torch.cuda.is_available()==True)"
      ],
      "metadata": {
        "id": "28RhXMtDoLzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e 'git+https://github.com/axolotl-ai-cloud/axolotl.git@78b42a3fe13c49e317bc116b9999c30e070322cc#egg=axolotl' # ensures the same version we used in the course"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty1xKmT5oSpq",
        "outputId": "22d09644-efb2-475a-c86d-4c42274e28a3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining axolotl from git+https://github.com/axolotl-ai-cloud/axolotl.git@78b42a3fe13c49e317bc116b9999c30e070322cc#egg=axolotl\n",
            "  Skipping because already up-to-date.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers@ git+https://github.com/huggingface/transformers.git@026a173a64372e9602a16523b8fae9de4b0ff428 (from axolotl)\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision 026a173a64372e9602a16523b8fae9de4b0ff428) to /tmp/pip-install-85viydn7/transformers_8c90db545246461a84bc7fc101271c5c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-85viydn7/transformers_8c90db545246461a84bc7fc101271c5c\n",
            "  Running command git rev-parse -q --verify 'sha^026a173a64372e9602a16523b8fae9de4b0ff428'\n",
            "  Running command git fetch -q https://github.com/huggingface/transformers.git 026a173a64372e9602a16523b8fae9de4b0ff428\n",
            "  Running command git checkout -q 026a173a64372e9602a16523b8fae9de4b0ff428\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 026a173a64372e9602a16523b8fae9de4b0ff428\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe (from axolotl)\n",
            "  Cloning https://github.com/lm-sys/FastChat.git (to revision 27a05b04a35510afb1d767ae7e5990cbd278f8fe) to /tmp/pip-install-85viydn7/fschat_e34e07fbb44a447f85e210041f77ea29\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lm-sys/FastChat.git /tmp/pip-install-85viydn7/fschat_e34e07fbb44a447f85e210041f77ea29\n",
            "  Running command git rev-parse -q --verify 'sha^27a05b04a35510afb1d767ae7e5990cbd278f8fe'\n",
            "  Running command git fetch -q https://github.com/lm-sys/FastChat.git 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Running command git checkout -q 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Resolved https://github.com/lm-sys/FastChat.git to commit 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging==23.2 (from axolotl)\n",
            "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting peft==0.11.1 (from axolotl)\n",
            "  Using cached peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tokenizers==0.19.1 (from axolotl)\n",
            "  Using cached tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting bitsandbytes==0.43.3 (from axolotl)\n",
            "  Using cached bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting accelerate==0.32.0 (from axolotl)\n",
            "  Using cached accelerate-0.32.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting pydantic==2.6.3 (from axolotl)\n",
            "  Using cached pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
            "Collecting addict (from axolotl)\n",
            "  Using cached addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fire (from axolotl)\n",
            "  Using cached fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.12/dist-packages (from axolotl) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from axolotl) (2.32.4)\n",
            "Collecting datasets==2.19.1 (from axolotl)\n",
            "  Using cached datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.2.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.21.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.8.1)\n",
            "Collecting optimum==1.16.2 (from axolotl)\n",
            "  Using cached optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.1.9)\n",
            "Collecting colorama (from axolotl)\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from axolotl) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from axolotl) (2.0.2)\n",
            "Collecting evaluate==0.4.1 (from axolotl)\n",
            "  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from axolotl) (1.16.1)\n",
            "Collecting scikit-learn==1.2.2 (from axolotl)\n",
            "  Using cached scikit-learn-1.2.2.tar.gz (7.3 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.12/dist-packages (from axolotl) (12.0.0)\n",
            "Collecting art (from axolotl)\n",
            "  Using cached art-6.5-py3-none-any.whl.metadata (72 kB)\n",
            "Collecting gradio==3.50.2 (from axolotl)\n",
            "  Using cached gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from axolotl) (2.19.0)\n",
            "Collecting python-dotenv==1.0.1 (from axolotl)\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting autoawq>=0.2.5 (from axolotl)\n",
            "  Using cached autoawq-0.2.9.tar.gz (74 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting s3fs (from axolotl)\n",
            "  Using cached s3fs-2025.7.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.12/dist-packages (from axolotl) (2025.3.0)\n",
            "Collecting trl==0.9.6 (from axolotl)\n",
            "  Using cached trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting zstandard==0.22.0 (from axolotl)\n",
            "  Using cached zstandard-0.22.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.12/dist-packages (from axolotl) (1.8.7)\n",
            "Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.12/dist-packages (from axolotl) (2.2.2)\n",
            "Collecting xformers>=0.0.25.post1 (from axolotl)\n",
            "  Using cached xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting numpy>=1.24.4 (from axolotl)\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate==0.32.0->axolotl) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from accelerate==0.32.0->axolotl) (0.34.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from accelerate==0.32.0->axolotl) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1->axolotl) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1->axolotl) (18.1.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.19.1->axolotl)\n",
            "  Using cached pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1->axolotl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1->axolotl) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1->axolotl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1->axolotl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1->axolotl) (0.70.16)\n",
            "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1->axolotl)\n",
            "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.19.1->axolotl) (3.12.15)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1->axolotl)\n",
            "  Using cached responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.2->axolotl)\n",
            "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (0.6.1)\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.2->axolotl)\n",
            "  Using cached gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio==3.50.2->axolotl)\n",
            "  Using cached MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (3.10.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (3.11.2)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio==3.50.2->axolotl)\n",
            "  Using cached pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (0.0.20)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio==3.50.2->axolotl) (0.35.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2->axolotl)\n",
            "  Using cached websockets-11.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting coloredlogs (from optimum==1.16.2->axolotl)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from optimum==1.16.2->axolotl) (1.13.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.6.3->axolotl) (0.7.0)\n",
            "Collecting pydantic-core==2.16.3 (from pydantic==2.6.3->axolotl)\n",
            "  Using cached pydantic_core-2.16.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.2.2->axolotl) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.2.2->axolotl) (3.6.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->axolotl) (12.1.105)\n",
            "Collecting tyro>=0.5.11 (from trl==0.9.6->axolotl)\n",
            "  Using cached tyro-0.9.28-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->axolotl) (12.8.93)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (from autoawq>=0.2.5->axolotl) (3.4.0)\n",
            "INFO: pip is looking at multiple versions of autoawq to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting autoawq>=0.2.5 (from axolotl)\n",
            "  Using cached autoawq-0.2.8.tar.gz (71 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Using cached autoawq-0.2.7.post3-py3-none-any.whl.metadata (18 kB)\n",
            "  Using cached autoawq-0.2.7.post2-py3-none-any.whl.metadata (18 kB)\n",
            "  Using cached autoawq-0.2.7.post1-py3-none-any.whl.metadata (18 kB)\n",
            "  Using cached autoawq-0.2.7-py3-none-any.whl.metadata (18 kB)\n",
            "\u001b[31mERROR: Cannot install axolotl and axolotl==0.4.1 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    axolotl 0.4.1 depends on transformers 4.44.0.dev0 (from git+https://github.com/huggingface/transformers.git@026a173a64372e9602a16523b8fae9de4b0ff428)\n",
            "    optimum 1.16.2 depends on transformers>=4.26.0\n",
            "    peft 0.11.1 depends on transformers\n",
            "    trl 0.9.6 depends on transformers>=4.31.0\n",
            "    autoawq 0.2.9 depends on transformers>=4.45.0\n",
            "    axolotl 0.4.1 depends on transformers 4.44.0.dev0 (from git+https://github.com/huggingface/transformers.git@026a173a64372e9602a16523b8fae9de4b0ff428)\n",
            "    optimum 1.16.2 depends on transformers>=4.26.0\n",
            "    peft 0.11.1 depends on transformers\n",
            "    trl 0.9.6 depends on transformers>=4.31.0\n",
            "    autoawq 0.2.8 depends on transformers<=4.47.1 and >=4.45.0\n",
            "    axolotl 0.4.1 depends on transformers 4.44.0.dev0 (from git+https://github.com/huggingface/transformers.git@026a173a64372e9602a16523b8fae9de4b0ff428)\n",
            "    optimum 1.16.2 depends on transformers>=4.26.0\n",
            "    peft 0.11.1 depends on transformers\n",
            "    trl 0.9.6 depends on transformers>=4.31.0\n",
            "    autoawq 0.2.7.post3 depends on transformers>=4.45.0\n",
            "    axolotl 0.4.1 depends on datasets==2.19.1\n",
            "    evaluate 0.4.1 depends on datasets>=2.0.0\n",
            "    optimum 1.16.2 depends on datasets\n",
            "    trl 0.9.6 depends on datasets\n",
            "    autoawq 0.2.7.post2 depends on datasets>=2.20\n",
            "    axolotl 0.4.1 depends on datasets==2.19.1\n",
            "    evaluate 0.4.1 depends on datasets>=2.0.0\n",
            "    optimum 1.16.2 depends on datasets\n",
            "    trl 0.9.6 depends on datasets\n",
            "    autoawq 0.2.7.post1 depends on datasets>=2.20\n",
            "    axolotl 0.4.1 depends on torch==2.2.2\n",
            "    accelerate 0.32.0 depends on torch>=1.10.0\n",
            "    bitsandbytes 0.43.3 depends on torch\n",
            "    optimum 1.16.2 depends on torch>=1.11\n",
            "    peft 0.11.1 depends on torch>=1.13.0\n",
            "    trl 0.9.6 depends on torch>=1.4.0\n",
            "    autoawq 0.2.7 depends on torch>=2.5.1\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision==0.17.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZP6hdRTzs8wR",
        "outputId": "e82b5c1d-9bd4-43c5-9af5-a022911978d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.17.2\n",
            "  Downloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.2) (2.0.2)\n",
            "Collecting torch==2.2.2 (from torchvision==0.17.2)\n",
            "  Downloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.17.2) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision==0.17.2) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision==0.17.2) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision==0.17.2) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision==0.17.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision==0.17.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->torchvision==0.17.2) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->torchvision==0.17.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->torchvision==0.17.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->torchvision==0.17.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->torchvision==0.17.2)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->torchvision==0.17.2)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->torchvision==0.17.2)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->torchvision==0.17.2)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->torchvision==0.17.2)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->torchvision==0.17.2)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->torchvision==0.17.2)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->torchvision==0.17.2)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->torchvision==0.17.2) (12.8.93)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.2->torchvision==0.17.2) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.2->torchvision==0.17.2) (1.3.0)\n",
            "Downloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0\n",
            "    Uninstalling torch-2.8.0:\n",
            "      Successfully uninstalled torch-2.8.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision"
                ]
              },
              "id": "fcd43440c2fb45009863d1c57b33c6d3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ce75cb",
        "outputId": "22411d84-7836-411f-bf74-817c81e7dc90"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import accelerate\n",
        "\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"Torchvision version: {torchvision.__version__}\")\n",
        "print(f\"Accelerate version: {accelerate.__version__}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.8.0+cu128\n",
            "Torchvision version: 0.23.0+cu126\n",
            "Accelerate version: 1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "train_config = \"\"\"\n",
        "# model params\n",
        "base_model: unsloth/Meta-Llama-3.1-8B-Instruct\n",
        "\n",
        "# dataset params\n",
        "datasets:\n",
        "  - path: jaydenccc/AI_Storyteller_Dataset\n",
        "    type:\n",
        "      system_prompt: \"You are an amazing storyteller. From the following synopsis, create an engaging story.\"\n",
        "      field_system: system\n",
        "      field_instruction: synopsis\n",
        "      field_output: short_story\n",
        "      format: \"<|user|>\\n {instruction} </s>\\n<|assistant|>\"\n",
        "      no_input_format: \"<|user|> {instruction} </s>\\n<|assistant|>\"\n",
        "\n",
        "output_dir: ./models/Llama3_Storyteller2\n",
        "\n",
        "\n",
        "# model params\n",
        "sequence_length: 512\n",
        "bf16: auto\n",
        "tf32: false\n",
        "\n",
        "# training params\n",
        "micro_batch_size: 1\n",
        "num_epochs: 1\n",
        "optimizer: adamw_bnb_8bit\n",
        "learning_rate: 0.0002\n",
        "\n",
        "logging_steps: 1\n",
        "\n",
        "\n",
        "# LoRA\n",
        "adapter: lora\n",
        "\n",
        "lora_r: 16\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.05\n",
        "\n",
        "lora_target_linear: true\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Convert the YAML string to a Python dictionary\n",
        "yaml_dict = yaml.safe_load(train_config)\n",
        "\n",
        "\n",
        "# Write the YAML file\n",
        "with open(\"advanced_train_lora.yml\", 'w') as file:\n",
        "    yaml.dump(yaml_dict, file)\n"
      ],
      "metadata": {
        "id": "-QZAB4WPpEG8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "train_config = \"\"\"\n",
        "# model params\n",
        "base_model: unsloth/Meta-Llama-3.1-8B-Instruct\n",
        "\n",
        "# dataset params\n",
        "datasets:\n",
        "  - path: jaydenccc/AI_Storyteller_Dataset\n",
        "    type:\n",
        "      system_prompt: \"You are an amazing storyteller. From the following synopsis, create an engaging story.\"\n",
        "      field_system: system\n",
        "      field_instruction: synopsis\n",
        "      field_output: short_story\n",
        "      format: \"<|user|>\\n {instruction} </s>\\n<|assistant|>\"\n",
        "      no_input_format: \"<|user|> {instruction} </s>\\n<|assistant|>\"\n",
        "\n",
        "output_dir: ./models/Llama3_Storyteller2\n",
        "\n",
        "\n",
        "# model params\n",
        "sequence_length: 512\n",
        "bf16: auto\n",
        "tf32: false\n",
        "\n",
        "# training params\n",
        "micro_batch_size: 1\n",
        "num_epochs: 1\n",
        "optimizer: adamw_bnb_8bit\n",
        "learning_rate: 0.0002\n",
        "\n",
        "logging_steps: 1\n",
        "\n",
        "\n",
        "# Gradient Accumulation\n",
        "gradient_accumulation_steps: 1\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Convert the YAML string to a Python dictionary\n",
        "yaml_dict = yaml.safe_load(train_config)\n",
        "\n",
        "\n",
        "# Write the YAML file\n",
        "with open(\"advanced_train_Gradient_Accumulation.yml\", 'w') as file:\n",
        "    yaml.dump(yaml_dict, file)\n"
      ],
      "metadata": {
        "id": "uXCBowYVpziL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "train_config = \"\"\"\n",
        "# model params\n",
        "base_model: unsloth/Meta-Llama-3.1-8B-Instruct\n",
        "\n",
        "# dataset params\n",
        "datasets:\n",
        "  - path: jaydenccc/AI_Storyteller_Dataset\n",
        "    type:\n",
        "      system_prompt: \"You are an amazing storyteller. From the following synopsis, create an engaging story.\"\n",
        "      field_system: system\n",
        "      field_instruction: synopsis\n",
        "      field_output: short_story\n",
        "      format: \"<|user|>\\n {instruction} </s>\\n<|assistant|>\"\n",
        "      no_input_format: \"<|user|> {instruction} </s>\\n<|assistant|>\"\n",
        "\n",
        "output_dir: ./models/Llama3_Storyteller2\n",
        "\n",
        "\n",
        "# model params\n",
        "sequence_length: 512\n",
        "bf16: auto\n",
        "tf32: false\n",
        "\n",
        "# training params\n",
        "micro_batch_size: 1\n",
        "num_epochs: 1\n",
        "optimizer: adamw_bnb_8bit\n",
        "learning_rate: 0.0002\n",
        "\n",
        "logging_steps: 1\n",
        "\n",
        "\n",
        "# Gradient Checkpointing\n",
        "gradient_checkpointing: true\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Convert the YAML string to a Python dictionary\n",
        "yaml_dict = yaml.safe_load(train_config)\n",
        "\n",
        "\n",
        "# Write the YAML file\n",
        "with open(\"advanced_train_Gradient_Checkpointing.yml\", 'w') as file:\n",
        "    yaml.dump(yaml_dict, file)\n"
      ],
      "metadata": {
        "id": "BJ0GGV_QqCrE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch -m axolotl.cli.train advanced_train_lora.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c3YpxvOr1gs",
        "outputId": "5ac9b63e-a2a0-4c58-d277-13c2c610eb95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/usr/local/bin/accelerate\", line 4, in <module>\n",
            "    from accelerate.commands.accelerate_cli import main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/__init__.py\", line 16, in <module>\n",
            "    from .accelerator import Accelerator\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\", line 32, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/usr/bin/python3: Error while finding module specification for 'axolotl.cli.train' (ModuleNotFoundError: No module named 'axolotl')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 1235, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 823, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'axolotl.cli.train', 'advanced_train_lora.yml']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch -m axolotl.cli.train advanced_train_Gradient_Accumulation.yml.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fouB0otyqnDl",
        "outputId": "b2931397-52d0-4c55-fd18-eea4315435ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/usr/bin/python3: Error while finding module specification for 'axolotl.cli.train' (ModuleNotFoundError: No module named 'axolotl')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 1235, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 823, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'axolotl.cli.train', 'advanced_train_Gradient_Accumulation.yml.yml']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch -m axolotl.cli.train advanced_train_Gradient_Checkpointing.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYIQ1eNQqnZX",
        "outputId": "85488672-f4e2-4c9c-aafa-b6fe5610a9d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/usr/bin/python3: Error while finding module specification for 'axolotl.cli.train' (ModuleNotFoundError: No module named 'axolotl')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 1235, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 823, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'axolotl.cli.train', 'advanced_train_Gradient_Checkpointing.yml']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Merge the trained adapter\n",
        "!accelerate launch -m axolotl.cli.merge_lora advanced_train.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4y6TIuvpTVK",
        "outputId": "6fad697d-6d04-4e49-98f0-65d5be222da9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/usr/bin/python3: Error while finding module specification for 'axolotl.cli.merge_lora' (ModuleNotFoundError: No module named 'axolotl')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/accelerate_cli.py\", line 50, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 1235, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/accelerate/commands/launch.py\", line 823, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'axolotl.cli.merge_lora', 'advanced_train.yml']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LpUMS2c0x1jS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}